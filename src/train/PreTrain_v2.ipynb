{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "\n",
    "path_to_model_directory = '../model'\n",
    "\n",
    "# Add this path to sys.path\n",
    "if path_to_model_directory not in sys.path:\n",
    "    sys.path.append(path_to_model_directory)\n",
    "\n",
    "# Now you can import your class\n",
    "from PreTrainer import PreTrainer, validate_data_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the PreTrainer\n",
    "BATCH_SIZE = 32\n",
    "LR = 0.001\n",
    "EPOCHS = 10\n",
    "train_path = '/home/florsanders/adl_ai_tennis_coach/data/tenniset/shot_labels/train'\n",
    "val_path = '/home/florsanders/adl_ai_tennis_coach/data/tenniset/shot_labels/val'\n",
    "model_config_file = '/home/tawab/e6691-2024spring-project-TECO-as7092-gyt2107-fps2116/src/model/configs/default.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files: 2248\n",
      "Invalid Files: 30\n",
      "Valid Files: 2218\n",
      "Percentage of valid files: 98.66548042704626%\n"
     ]
    }
   ],
   "source": [
    "# Validate Train Data\n",
    "train_invalid_data_path = validate_data_format(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files: 565\n",
      "Invalid Files: 5\n",
      "Valid Files: 560\n",
      "Percentage of valid files: 99.11504424778761%\n"
     ]
    }
   ],
   "source": [
    "# Validate Val Data\n",
    "val_invalid_data_path = validate_data_format(val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write list to a JSON file\n",
    "with open('train_invalid_data.json', 'w') as file:\n",
    "    json.dump(train_invalid_data_path, file)\n",
    "with open('val_invalid_data.json', 'w') as file:\n",
    "    json.dump(val_invalid_data_path, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping V006_0068: Incorrect dimensions - positions_2d (0, 2), poses_3d (0,)\n",
      "Skipping V006_0179: Incorrect dimensions - positions_2d (0, 2), poses_3d (0,)\n",
      "Skipping V007_0183: Incorrect dimensions - positions_2d (0, 2), poses_3d (0,)\n",
      "Skipping V007_0184: Incorrect dimensions - positions_2d (0, 2), poses_3d (0,)\n",
      "Skipping V008_0003: Data file not found.\n",
      "Skipping V008_0056: Incorrect dimensions - positions_2d (0, 2), poses_3d (0,)\n",
      "Skipping V008_0156: Incorrect dimensions - positions_2d (0, 2), poses_3d (0,)\n",
      "Skipping V009_0017: Incorrect dimensions - positions_2d (0, 2), poses_3d (0,)\n",
      "Skipping V009_0924: Incorrect dimensions - positions_2d (0, 2), poses_3d (0,)\n",
      "Skipping V009_0947: Incorrect dimensions - positions_2d (0, 2), poses_3d (0,)\n",
      "Skipping V009_0948: Incorrect dimensions - positions_2d (0, 2), poses_3d (0,)\n",
      "Skipping V009_1045: Incorrect dimensions - positions_2d (0, 2), poses_3d (0,)\n",
      "Skipping V009_1281: Incorrect dimensions - positions_2d (0, 2), poses_3d (0,)\n",
      "Skipping V009_1282: Incorrect dimensions - positions_2d (0, 2), poses_3d (0,)\n",
      "Skipping V009_1542: Incorrect dimensions - positions_2d (0, 2), poses_3d (0,)\n",
      "Skipping V009_1553: Incorrect dimensions - positions_2d (0, 2), poses_3d (0,)\n",
      "Skipping V009_1734: Incorrect dimensions - positions_2d (0, 2), poses_3d (0,)\n",
      "Skipping V009_1742: Incorrect dimensions - positions_2d (0, 2), poses_3d (0,)\n",
      "Skipping V009_1860: Incorrect dimensions - positions_2d (0, 2), poses_3d (0,)\n",
      "Skipping V006_0066: Incorrect dimensions - positions_2d (0, 2), poses_3d (0,)\n",
      "Skipping V006_0178: Incorrect dimensions - positions_2d (0, 2), poses_3d (0,)\n",
      "Skipping V009_1046: Incorrect dimensions - positions_2d (0, 2), poses_3d (0,)\n",
      "Skipping V009_1639: Incorrect dimensions - positions_2d (0, 2), poses_3d (0,)\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Trainer Setup\n",
    "trainer = PreTrainer(\n",
    "    batch_size=BATCH_SIZE,\n",
    "    lr=LR,\n",
    "    epochs=EPOCHS,\n",
    "    train_path=train_path,\n",
    "    val_path=val_path,\n",
    "    model_config_path=model_config_file,\n",
    "    model_save_path='trained_models'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:17<00:00,  4.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 6.9366803589001504\n",
      "Validation Loss: 2.0761478741963706\n",
      "Saving model at trained_models with validation loss of 2.0761478741963706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:15<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 2.0405447617383072\n",
      "Validation Loss: 1.7640170653661091\n",
      "Saving model at trained_models with validation loss of 1.7640170653661091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:15<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 1.9298397940649112\n",
      "Validation Loss: 1.7268546554777358\n",
      "Saving model at trained_models with validation loss of 1.7268546554777358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:15<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 1.9005043288351784\n",
      "Validation Loss: 1.7138367295265198\n",
      "Saving model at trained_models with validation loss of 1.7138367295265198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:15<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 1.8822210640974448\n",
      "Validation Loss: 1.6981180177794561\n",
      "Saving model at trained_models with validation loss of 1.6981180177794561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:15<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 1.910371723309369\n",
      "Validation Loss: 1.692180057366689\n",
      "Saving model at trained_models with validation loss of 1.692180057366689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:15<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 1.86625565273661\n",
      "Validation Loss: 1.6973976360427008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:15<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 1.8665103895563475\n",
      "Validation Loss: 1.7120945784780714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:15<00:00,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 1.8387023546326329\n",
      "Validation Loss: 1.6665880613856845\n",
      "Saving model at trained_models with validation loss of 1.6665880613856845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:15<00:00,  4.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 1.7953675884596059\n",
      "Validation Loss: 1.5780009494887457\n",
      "Saving model at trained_models with validation loss of 1.5780009494887457\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for Masking Logic Used in the Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask and data verified successfully for batch 0\n",
      "Mask and data verified successfully for batch 1\n",
      "Mask and data verified successfully for batch 2\n",
      "Mask and data verified successfully for batch 3\n",
      "Mask and data verified successfully for batch 4\n",
      "Mask and data verified successfully for batch 5\n",
      "Mask and data verified successfully for batch 6\n",
      "Mask and data verified successfully for batch 7\n",
      "Mask and data verified successfully for batch 8\n",
      "Mask and data verified successfully for batch 9\n",
      "Mask and data verified successfully for batch 10\n",
      "Mask and data verified successfully for batch 11\n",
      "Mask and data verified successfully for batch 12\n",
      "Mask and data verified successfully for batch 13\n",
      "Mask and data verified successfully for batch 14\n",
      "Mask and data verified successfully for batch 15\n",
      "Mask and data verified successfully for batch 16\n",
      "Mask and data verified successfully for batch 17\n",
      "Mask and data verified successfully for batch 18\n",
      "Mask and data verified successfully for batch 19\n",
      "Mask and data verified successfully for batch 20\n",
      "Mask and data verified successfully for batch 21\n",
      "Mask and data verified successfully for batch 22\n",
      "Mask and data verified successfully for batch 23\n",
      "Mask and data verified successfully for batch 24\n",
      "Mask and data verified successfully for batch 25\n",
      "Mask and data verified successfully for batch 26\n",
      "Mask and data verified successfully for batch 27\n",
      "Mask and data verified successfully for batch 28\n",
      "Mask and data verified successfully for batch 29\n",
      "Mask and data verified successfully for batch 30\n",
      "Mask and data verified successfully for batch 31\n",
      "Shape of original targets: torch.Size([32, 41, 17, 3])\n",
      "Shape of pose_graphs (after padding): torch.Size([32, 41, 17, 3])\n",
      "Shape of masks (after padding and expanding): torch.Size([32, 41, 17, 3])\n",
      "Shape of masked targets: torch.Size([32, 41, 17, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# Define the maximum sequence length based on your previous logic\n",
    "max_length = 10 + 31\n",
    "\n",
    "# Create target tensor initialized to a specific value for easy verification (e.g., all ones)\n",
    "targets = torch.ones([32, max_length, 17, 3], dtype=torch.float32)\n",
    "\n",
    "# Create masks and pose_graphs with varying sequence lengths\n",
    "masks = []\n",
    "pose_graphs = []\n",
    "\n",
    "for i in range(32):\n",
    "    length = 10 + i  # Variable sequence lengths\n",
    "    pose_graphs.append(torch.ones(length, 17, 3))  # Simulate real data\n",
    "    masks.append(torch.ones(length, dtype=torch.bool))  # True where data is valid\n",
    "\n",
    "# Pad pose_graphs and masks to uniform lengths\n",
    "pose_graphs_padded = pad_sequence(pose_graphs, batch_first=True)\n",
    "masks_padded = pad_sequence(masks, batch_first=True, padding_value=0)\n",
    "\n",
    "# Expand the mask to match targets' dimensions\n",
    "expanded_masks = masks_padded.unsqueeze(-1).unsqueeze(-1).expand(-1, -1, 17, 3)\n",
    "\n",
    "# Apply the mask to the targets\n",
    "masked_targets = targets * expanded_masks\n",
    "\n",
    "# Verification steps\n",
    "for i in range(32):\n",
    "    expected_length = 10 + i\n",
    "    actual_mask = expanded_masks[i]\n",
    "    actual_data = masked_targets[i]\n",
    "\n",
    "    # Check the areas expected to be masked\n",
    "    if torch.any(actual_data[:expected_length] != 1):\n",
    "        print(f\"Error: Data corruption in unmasked area for batch {i}\")\n",
    "    if torch.any(actual_data[expected_length:] != 0):\n",
    "        print(f\"Error: Incomplete masking in padded area for batch {i}\")\n",
    "    else:\n",
    "        print(f\"Mask and data verified successfully for batch {i}\")\n",
    "\n",
    "# Print the shape of tensors to verify\n",
    "print(\"Shape of original targets:\", targets.shape)\n",
    "print(\"Shape of pose_graphs (after padding):\", pose_graphs_padded.shape)\n",
    "print(\"Shape of masks (after padding and expanding):\", expanded_masks.shape)\n",
    "print(\"Shape of masked targets:\", masked_targets.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "teco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
