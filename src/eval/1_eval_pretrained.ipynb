{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Pre-Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_geometric.data import Data, Batch\n",
    "\n",
    "plt.style.use(\"tableau-colorblind10\")\n",
    "plt.rcParams[\"font.size\"] = 18\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add base path to the system path\n",
    "base_path = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "if not base_path in sys.path:\n",
    "    sys.path.append(base_path)\n",
    "print(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import code from other directories\n",
    "from data.data import scale_3d_poses, scale_2d_positions\n",
    "from data.visualizations import make_3d_figax, animate_3d_pose, plot_3d_pose\n",
    "from model.model_builder import build_tennis_embedder\n",
    "from model.data import TennisDataset, build_human_pose_edge_index\n",
    "from train.PreTrainer import my_collate_fn, PreTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory to save figures\n",
    "figures_dir = \"./figures\"\n",
    "os.makedirs(figures_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define configuration path\n",
    "model_config_path = os.path.join(base_path, \"model\", \"configs\", \"default.yaml\")\n",
    "\n",
    "# Define model weights path\n",
    "model_weights_path = os.path.join(base_path, os.pardir, \"models\", \"best_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = build_tennis_embedder(model_config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load weights\n",
    "model_weights = torch.load(model_weights_path, map_location=torch.device(device))\n",
    "model.load_state_dict(model_weights)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "LR = 0.001\n",
    "EPOCHS = 50\n",
    "data_path = os.path.abspath(os.path.join(os.getcwd(), os.pardir, os.pardir, 'data'))\n",
    "labels_path = os.path.join(data_path, 'tenniset', 'shot_labels')\n",
    "train_path = os.path.join(labels_path, 'train')\n",
    "val_path = os.path.join(labels_path, 'val')\n",
    "test_path = os.path.join(labels_path, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer Setup\n",
    "trainer = PreTrainer(\n",
    "    batch_size=BATCH_SIZE,\n",
    "    lr=LR,\n",
    "    epochs=EPOCHS,\n",
    "    train_path=train_path,\n",
    "    val_path=val_path,\n",
    "    model_config_path=model_config_path,\n",
    "    model_save_path='trained_models'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.load_pretrained_model(model_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test_trained_model(test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test dataset\n",
    "data_path = os.path.abspath(os.path.join(os.getcwd(), os.pardir, os.pardir, 'data'))\n",
    "labels_path = os.path.join(data_path, 'tenniset', 'shot_labels')\n",
    "test_path = os.path.join(labels_path, 'test')\n",
    "test_set = TennisDataset(labels_path=test_path)\n",
    "test_loader = DataLoader(\n",
    "    test_set, batch_size=1, shuffle=False, collate_fn=my_collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find max sequence length\n",
    "max_sequence_length = 0\n",
    "\n",
    "for poses_3d, positions_2d, pose_graphs, targets, mask in (test_loader):\n",
    "    if len(positions_2d[0]) > max_sequence_length:\n",
    "        max_sequence_length = len(positions_2d[0])\n",
    "\n",
    "print(f\"Maximum sequence length is {max_sequence_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert pose 3D to torch geometric graph\n",
    "start_nodes, end_nodes = build_human_pose_edge_index()\n",
    "edge_index = torch.tensor([start_nodes, end_nodes], dtype=torch.long)\n",
    "\n",
    "def construct_graph_batch_from_pose_3d(pose_3d):\n",
    "    x = torch.tensor(pose_3d, dtype=torch.float32)\n",
    "    graph = Data(x=x, edge_index=edge_index)\n",
    "    graph_batch = Batch.from_data_list([graph])\n",
    "    return graph_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_pose_sequence(model, pose_3d, positions_2d):\n",
    "    # Determine the number of predictions to make\n",
    "    sequence_length = len(positions_2d)\n",
    "    predicted_pose_sequence = np.zeros((sequence_length, 17, 3))\n",
    "\n",
    "    # Create first pose graph batch\n",
    "    graph_batch = construct_graph_batch_from_pose_3d(pose_3d)\n",
    "\n",
    "    # Make the predictions\n",
    "    with torch.no_grad():\n",
    "        for i in range(sequence_length):\n",
    "            # Encode current position as batch\n",
    "            pos_batch = torch.unsqueeze(torch.unsqueeze(positions_2d[i], 0), 0)\n",
    "\n",
    "            # Model forward to predict next pose\n",
    "            pose_estimate = model.forward([graph_batch.to(device)], pos_batch.to(device))\n",
    "            pose_estimate = pose_estimate.to(\"cpu\").clone().detach().numpy().squeeze()\n",
    "            \n",
    "            # Update pose sequence\n",
    "            predicted_pose_sequence[i] = pose_estimate\n",
    "\n",
    "            # Encode current prediction as next pose\n",
    "            graph_batch = construct_graph_batch_from_pose_3d(pose_estimate)\n",
    "    \n",
    "    return predicted_pose_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_pose_sequence(model, poses_3d, positions_2d):\n",
    "    # Determine the number of predictions to make\n",
    "    sequence_length = len(positions_2d)\n",
    "    known_poses_length = len(poses_3d)\n",
    "    assert known_poses_length > 0, \"At least 1 known pose must be provided for evaluation\"\n",
    "    predicted_pose_sequence = np.zeros((sequence_length, 17, 3))\n",
    "\n",
    "    # Create first pose graph batch\n",
    "    graph_batch = construct_graph_batch_from_pose_3d(poses_3d[0])\n",
    "\n",
    "    # Make the predictions\n",
    "    with torch.no_grad():\n",
    "        for i in range(sequence_length):\n",
    "            # Create pose graph batch\n",
    "            if i < known_poses_length:\n",
    "                # Use known pose for first N samples\n",
    "                graph_batch = construct_graph_batch_from_pose_3d(poses_3d[i])\n",
    "            else:\n",
    "                # Construct batch based on previous prediction\n",
    "                graph_batch = construct_graph_batch_from_pose_3d(pose_estimate)\n",
    "\n",
    "            # Encode current position as batch\n",
    "            pos_batch = torch.unsqueeze(torch.unsqueeze(positions_2d[i], 0), 0)\n",
    "\n",
    "            # Model forward to predict next pose\n",
    "            pose_estimate = model.forward([graph_batch.to(device)], pos_batch.to(device))\n",
    "            pose_estimate = pose_estimate.to(\"cpu\").clone().detach().numpy().squeeze()\n",
    "            \n",
    "            # Update pose sequence\n",
    "            predicted_pose_sequence[i] = pose_estimate\n",
    "\n",
    "    return predicted_pose_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction divergence over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many initial poses to feed\n",
    "n_known_poses = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep track of MSE statistics\n",
    "mse_counter = np.zeros(max_sequence_length)\n",
    "mse_mean = np.zeros(max_sequence_length)\n",
    "mse_squared_mean = np.zeros(max_sequence_length)\n",
    "mse_min = np.zeros(max_sequence_length)\n",
    "mse_max = np.zeros(max_sequence_length)\n",
    "\n",
    "# Compute MSE for each frame\n",
    "for poses_3d, positions_2d, pose_graphs, targets, mask in tqdm(test_loader):\n",
    "    # Determine the sequence length\n",
    "    sequence_length = len(positions_2d[0])\n",
    "    \n",
    "    # Predict pose sequence based on only the first frame's pose\n",
    "    pose_predictions = predict_pose_sequence(model, poses_3d[0][:n_known_poses], positions_2d[0])\n",
    "\n",
    "    # Compute frame-to-frame MSE\n",
    "    predictions_mse = np.mean((pose_predictions - targets.numpy().squeeze())**2, axis=(1, 2))\n",
    "\n",
    "    # Compute statistics\n",
    "    mse_counter[:sequence_length] += 1\n",
    "    n = mse_counter[:sequence_length]\n",
    "    mse_mean[:sequence_length] = mse_mean[:sequence_length] * (n - 1) / n + predictions_mse / n\n",
    "    mse_squared_mean[:sequence_length] = mse_squared_mean[:sequence_length] * (n - 1) / n + predictions_mse**2 / n\n",
    "    mse_min[:sequence_length] = np.minimum(mse_min[:sequence_length], predictions_mse)\n",
    "    mse_max[:sequence_length] = np.maximum(mse_max[:sequence_length], predictions_mse) \n",
    "\n",
    "# Compute variance and standard deviation\n",
    "mse_variance = mse_squared_mean - mse_mean**2\n",
    "mse_std = np.sqrt(mse_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of segments with at least the given frame length\n",
    "fig, ax = plt.subplots(figsize=(8, 4.5))\n",
    "ax.plot(mse_counter)\n",
    "ax.grid(True)\n",
    "ax.set_xlabel(\"Frame\")\n",
    "ax.set_ylabel(\"#Segments\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,4.5))\n",
    "mask = (mse_mean > 0)\n",
    "assert np.count_nonzero(mask) == len(mask)\n",
    "mask = (mse_std > 0)\n",
    "show_n_frames = np.count_nonzero(mask)\n",
    "print(show_n_frames)\n",
    "ax.plot(\n",
    "    np.arange(len(mse_mean))[mask][n_known_poses-1:show_n_frames], \n",
    "    mse_mean[mask][n_known_poses-1:show_n_frames], \n",
    "    #label=r\"$\\mu$\", \n",
    "    color=\"tab:blue\"\n",
    ")\n",
    "ax.fill_between(\n",
    "    np.arange(len(mse_mean))[mask][n_known_poses-1:show_n_frames],\n",
    "    np.maximum(mse_mean[mask] - mse_std[mask], np.zeros(np.count_nonzero(mask)))[n_known_poses-1:show_n_frames],\n",
    "    (mse_mean[mask] + mse_std[mask])[n_known_poses-1:show_n_frames],\n",
    "    #label=r\"$\\mu$ +/- $\\sigma$\",\n",
    "    alpha=0.5,\n",
    "    color=\"tab:blue\",\n",
    ")\n",
    "ax.plot(\n",
    "    np.arange(len(mse_mean))[mask][:n_known_poses], \n",
    "    mse_mean[mask][:n_known_poses], \n",
    "    label=r\"$\\mu$\", \n",
    "    color=\"tab:green\"\n",
    ")\n",
    "ax.fill_between(\n",
    "    np.arange(len(mse_mean))[mask][:n_known_poses],\n",
    "    np.maximum(mse_mean[mask] - mse_std[mask], np.zeros(np.count_nonzero(mask)))[:n_known_poses],\n",
    "    (mse_mean[mask] + mse_std[mask])[:n_known_poses],\n",
    "    label=r\"$\\mu$ +/- $\\sigma$\",\n",
    "    alpha=0.5,\n",
    "    color=\"tab:green\",\n",
    ")\n",
    "ax.legend(loc=\"upper left\")\n",
    "ax.set_xlabel(\"Frame\")\n",
    "ax.set_ylabel(\"MSE\")\n",
    "ax.set_xlim(0, show_n_frames-1)\n",
    "ax.set_ylim(0)\n",
    "ax.grid(True)\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(figures_dir, f\"prediction_quality_drift_{n_known_poses}poses_{show_n_frames}.png\"), facecolor=\"white\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Animate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many initial poses to feed\n",
    "n_known_poses = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate directory to save prediction animations\n",
    "animations_dir = os.path.join(\"figures\", f\"animations_{n_known_poses}poses\")\n",
    "os.makedirs(animations_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_frame_prediction(\n",
    "    target, \n",
    "    prediction, \n",
    "    fig=None, \n",
    "    ax=None, \n",
    "    save_path=None,\n",
    "):\n",
    "    # Make figure  and axis\n",
    "    if fig is None or ax is None:\n",
    "        fig, ax = make_3d_figax()\n",
    "\n",
    "    # Plot target and prediction\n",
    "    fig, ax = plot_3d_pose(target, x_global=-separation/2, y_global=0, color=\"green\", fig=fig, ax=ax)\n",
    "    fig, ax = plot_3d_pose(prediction, x_global=separation/2, y_global=0, color=\"red\", fig=fig, ax=ax)\n",
    "\n",
    "    # Set ax properties\n",
    "    ax.set_aspect(\"equal\", adjustable=\"box\")\n",
    "    ax.view_init(elev=12, azim=-90)\n",
    "    #ax.set_axis_on()\n",
    "\n",
    "    # Sabe if desired\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path, dpi=300, facecolor=\"white\")\n",
    "    \n",
    "    return fig, ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute MSE for each frame\n",
    "for i, (poses_3d, positions_2d, pose_graphs, targets, mask) in enumerate(tqdm(test_loader)):\n",
    "    # Name sequence\n",
    "    sequence_name = f\"{i}\".zfill(4)\n",
    "    animation_path = os.path.join(animations_dir, f\"sequence_{sequence_name}.mp4\")\n",
    "    if os.path.exists(animation_path):\n",
    "        pass\n",
    "\n",
    "    # Determine the sequence length\n",
    "    targets = targets.numpy().squeeze()\n",
    "    sequence_length = len(targets)\n",
    "    print(len(targets))\n",
    "    assert sequence_length == len(positions_2d[0]), f\"Sequence length {sequence_length} does not match with {len(positions_2d[0])}\"\n",
    "    \n",
    "    # Predict pose sequence based on only the first frame's pose\n",
    "    pose_predictions = predict_pose_sequence(model, poses_3d[0][:n_known_poses], positions_2d[0])\n",
    "\n",
    "    # Plot frame predictions\n",
    "    for frame_index in [0, min(24, sequence_length-1)]:\n",
    "        frame_name = f\"{frame_index}\".zfill(2)\n",
    "        separation = 1\n",
    "        fig, ax = plot_frame_prediction(\n",
    "            targets[frame_index], \n",
    "            pose_predictions[frame_index], \n",
    "            save_path=os.path.join(animations_dir, f\"sequence_{sequence_name}_{frame_name}.png\"),\n",
    "        )\n",
    "        if i == 0:\n",
    "            plt.show()\n",
    "        plt.close(fig)\n",
    "\n",
    "    # Animate frame predictions\n",
    "    pose_3d = poses_3d[0][0].numpy() \n",
    "    fig, ax = make_3d_figax()\n",
    "    fig, ax = plot_frame_prediction(\n",
    "        pose_3d, \n",
    "        pose_3d, \n",
    "        fig=fig,\n",
    "        ax=ax,\n",
    "    )\n",
    "    def update_plot(frame_index, fig=fig, ax=ax):\n",
    "        ax.clear()\n",
    "        ax.set_axis_off()\n",
    "        if frame_index == 0:\n",
    "            fig, ax = plot_frame_prediction(\n",
    "                pose_3d, \n",
    "                pose_3d, \n",
    "                fig=fig,\n",
    "                ax=ax,\n",
    "            )\n",
    "        else:\n",
    "            fig, ax = plot_frame_prediction(\n",
    "                targets[frame_index-1], \n",
    "                pose_predictions[frame_index-1], \n",
    "                fig=fig,\n",
    "                ax=ax,\n",
    "            )\n",
    "    ani = animation.FuncAnimation(\n",
    "        fig, update_plot, sequence_length+1, interval=40\n",
    "    )\n",
    "    writer = animation.FFMpegWriter(fps=25)\n",
    "    ani.save(animation_path, writer=writer, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "teco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
