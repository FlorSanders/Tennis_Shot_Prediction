{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D -> 3D Data Processing\n",
    "Execution of this notebook is meant to follow `1_data_processing.ipynb`. \n",
    "\n",
    "The "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import cv2\n",
    "\n",
    "# Constants\n",
    "from __init__ import data_path\n",
    "from data_utils import read_segment_frames, read_segment_labels, visualize_frame_annotations, visualize_segment_labels\n",
    "from PoseLifter import PoseLifter\n",
    "# Choose dataset\n",
    "dataset_path = \"/home/florsanders/adl_ai_tennis_coach/data/tenniset\"\n",
    "write_path = \"/home/georgetamer/3d_poses\"\n",
    "segments_path = os.path.join(dataset_path, \"segments\")\n",
    "labels_path = os.path.join(dataset_path,\"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_frame(frame,\n",
    "              bbox,\n",
    "              crop_padding=50,\n",
    "            crop_img_width=256):\n",
    "    # Frame size\n",
    "    frame_height, frame_width = frame.shape[:2]\n",
    "\n",
    "    # Parse bounding box coords\n",
    "    if np.any(bbox == None):\n",
    "        return best_keypoints, best_bbox\n",
    "    x1, y1, x2, y2 = bbox\n",
    "    xc, yc =  (x1 + x2) / 2, (y1 + y2) / 2\n",
    "    w, h = abs(x2 - x1), abs(y2 - y1)\n",
    "    d = max(w, h) + crop_padding * 2\n",
    "\n",
    "    # Define cropping indices\n",
    "    x_crop1, x_crop2 = int(xc - d/2), int(xc + d/2)\n",
    "    y_crop1, y_crop2 = int(yc - d/2), int(yc + d/2)\n",
    "\n",
    "    # Make sure we don't crop past the edges of the frame\n",
    "    x_crop_offset = min(frame_width - x_crop2, max(-x_crop1, 0))\n",
    "    y_crop_offset = min(frame_height - y_crop2, max(-y_crop1, 0))\n",
    "    x_crop1 += x_crop_offset\n",
    "    x_crop2 += x_crop_offset\n",
    "    y_crop1 += y_crop_offset\n",
    "    y_crop2 += y_crop_offset\n",
    "    \n",
    "    # Crop image\n",
    "    img = frame[y_crop1:y_crop2,  x_crop1:x_crop2].copy()\n",
    "\n",
    "    # Resize img\n",
    "    scale = d / crop_img_width\n",
    "    img = cv2.resize(img, (crop_img_width, crop_img_width))\n",
    "    return img\n",
    "\n",
    "def detect_pose(\n",
    "    frame,\n",
    "    bbox,\n",
    "    crop_padding=50,\n",
    "    crop_img_width=256\n",
    "):\n",
    "\n",
    "    # Crop image\n",
    "    crop_padding=10\n",
    "    cropped_frame = crop_frame(frame, bbox, crop_padding,crop_img_width)\n",
    "\n",
    "    # Detect pose\n",
    "    should_show = False\n",
    "    result_generator = inferencer(cropped_frame, show=should_show, vis_out_dir=\"/home/georgetamer/3d_poses\", return_vis=True)\n",
    "    results = [result for result in result_generator]\n",
    "\n",
    "    # # Parse keypoints\n",
    "    # min_center_distance = np.inf\n",
    "    # result = results[0]\n",
    "    # prediction = result[\"predictions\"][0]\n",
    "    # item = prediction[0]\n",
    "    # keypoints = item[\"keypoints\"]\n",
    "\n",
    "    # Keep best results\n",
    "    min_center_distance = np.inf\n",
    "    for result in results:\n",
    "        print(\"result: \", result)\n",
    "        for prediction in result[\"predictions\"]:\n",
    "            for item in prediction:\n",
    "                # Parse item\n",
    "                # pose_bbox = item[\"bbox\"]\n",
    "                keypoints = item[\"keypoints\"]\n",
    "\n",
    "                # Parse bbox\n",
    "                # xb1, yb1, xb2, yb2 = pose_bbox[0]\n",
    "                # center_x = (xb1 + xb2) / 2\n",
    "                # center_y = (yb1 + yb2) / 2\n",
    "                # center_distance = ((crop_img_width / 2 - center_x)**2  + (crop_img_width / 2 - center_y)**2)**(1/2)\n",
    "\n",
    "                # # Keep track of best prediction\n",
    "                # if center_distance < min_center_distance:\n",
    "                #     min_center_distance = center_distance\n",
    "                #     best_keypoints = keypoints\n",
    "                #     best_bbox = pose_bbox[0]\n",
    "\n",
    "    return np.array(keypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_lifter = PoseLifter(\n",
    "    crop_fn=crop_frame,\n",
    "    dedup_heuristic_fn=\"TODO\"\n",
    ")\n",
    "\n",
    "pose_lifter.set_dataset_path(dataset_path)\n",
    "pose_lifter.set_write_path(write_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_lifter.extract_3d_poses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_path = os.path.join(segments_path, \"V009_0061.mp4\")\n",
    "print(\"Segment path\", seg_path)\n",
    "\n",
    "success = process_segment(\n",
    "    segment_path=seg_path, \n",
    "    labels_path=labels_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize\n",
    "from mmpose.apis import visualize\n",
    "\n",
    "# extract first frame from segment\n",
    "img_path = os.path.join(write_path, '000000.jpg')\n",
    "keypoints = np.load(sample_file, allow_pickle=True)\n",
    "keypoint_scores = None\n",
    "\n",
    "metainfo = 'config/_base_/datasets/coco.py'\n",
    "\n",
    "visualize(\n",
    "    img_path,\n",
    "    keypoints,\n",
    "    keypoint_scores,\n",
    "    metainfo=metainfo,\n",
    "    show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take heuristic such as max area, or largest x-span, y-span\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
