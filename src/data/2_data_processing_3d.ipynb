{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D -> 3D Data Processing\n",
    "Execution of this notebook is meant to follow `1_data_processing.ipynb`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Sample the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Constants\n",
    "from PoseLifter import PoseLifter\n",
    "from data_utils import crop_frame\n",
    "\n",
    "# Choose dataset\n",
    "dataset_path = \"/home/florsanders/adl_ai_tennis_coach/data/tenniset\"\n",
    "write_path = \"/home/georgetamer/3d_poses\"\n",
    "segments_path = os.path.join(dataset_path, \"segments\")\n",
    "labels_path = os.path.join(dataset_path,\"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heuristics import keep_largest_volume_3D_pose_heuristic\n",
    "\n",
    "pose_lifter = PoseLifter(\n",
    "    crop_fn=crop_frame,\n",
    "    dedup_heuristic_fn=keep_largest_volume_3D_pose_heuristic,\n",
    "    dataset_path=dataset_path,\n",
    "    write_path=write_path,\n",
    "    duplicate_work=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_lifter.extract_3d_poses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-process 3D Poses\n",
    "\n",
    "The extracted 3D poses are not oriented upright and their orientations are not consistent between frames.\n",
    "\n",
    "To resolve this, we match certain keypoints in the detected 3D poses by matching them with the correctly oriented 2D poses by finding the [best fitting rotation matrix between them](https://nghiaho.com/?page_id=671)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library reloading\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import utilities\n",
    "from data import (\n",
    "    read_segment_frames,\n",
    "    read_segment_2d_annotations, \n",
    "    read_segment_3d_annotations,\n",
    "    rotate_3d_poses,\n",
    "    rotate_pose_3d_to_match_2d,\n",
    ")\n",
    "from visualizations import (\n",
    "    make_3d_figax,\n",
    "    plot_3d_pose,\n",
    "    plot_2d_pose,\n",
    "    plot_img,\n",
    "    visualize_frame_2d_annotations,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data directories\n",
    "data_path = os.path.abspath(os.path.join(os.getcwd(), os.pardir, os.pardir, \"data\"))\n",
    "segments_path = os.path.join(data_path, \"tenniset\", \"shot_segments\")\n",
    "labels_path = os.path.join(data_path, \"tenniset\", \"shot_labels\")\n",
    "print(segments_path, len(os.listdir(segments_path)))\n",
    "print(labels_path, len(os.listdir(labels_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read segment files\n",
    "segment_files = np.sort(glob.glob(os.path.join(segments_path, \"*.mp4\")))\n",
    "n_segments = len(segment_files)\n",
    "print(\"Number of segments:\", n_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite = False\n",
    "for segment_path in tqdm(segment_files):\n",
    "    # Parse segment filename\n",
    "    segment_dir,  segment_filename = os.path.split(segment_path)\n",
    "    segment_name, segment_ext = os.path.splitext(segment_filename)\n",
    "    #print(f\"Processing {segment_name}...\")\n",
    "\n",
    "    # Avoid doing double work\n",
    "    btm_path = os.path.join(labels_path, f\"{segment_name}_player_btm_pose_3d_rot.npy\")\n",
    "    top_path = os.path.join(labels_path, f\"{segment_name}_player_top_pose_3d_rot.npy\")\n",
    "    if not overwrite and os.path.exists(btm_path) and os.path.exists(top_path):\n",
    "        continue\n",
    "\n",
    "    # Load annotations\n",
    "    try:\n",
    "        (\n",
    "            _,\n",
    "            _,\n",
    "            _,\n",
    "            _,\n",
    "            player_btm_pose_sequence,\n",
    "            player_top_pose_sequence,\n",
    "        ) = read_segment_2d_annotations(segment_path, labels_path=labels_path)\n",
    "        (\n",
    "            _,\n",
    "            _,\n",
    "            player_btm_pose_3d_sequence,\n",
    "            player_top_pose_3d_sequence,\n",
    "        ) = read_segment_3d_annotations(segment_path, labels_path=labels_path, use_rotated=False)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: missing annotation files for {segment_name}\")\n",
    "        continue\n",
    "        \n",
    "    n_frames = len(player_btm_pose_sequence)\n",
    "\n",
    "    # Rotate poses\n",
    "    player_btm_pose_3d_rot = rotate_3d_poses(\n",
    "        player_btm_pose_3d_sequence, player_btm_pose_sequence\n",
    "    )\n",
    "    player_top_pose_3d_rot = rotate_3d_poses(\n",
    "        player_btm_pose_3d_sequence, player_btm_pose_sequence\n",
    "    )\n",
    "\n",
    "    # Save rotated poses\n",
    "    np.save(btm_path, player_btm_pose_3d_rot)\n",
    "    np.save(top_path, player_top_pose_3d_rot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reset validity labels\n",
    "\n",
    "Label all data points as valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data directory\n",
    "data_path = os.path.abspath(os.path.join(os.getcwd(), os.pardir, os.pardir, \"data\"))\n",
    "labels_path = os.path.join(data_path, \"tenniset\", \"shot_labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_files = np.sort(glob.glob(os.path.join(labels_path, \"*_info.json\")))\n",
    "for info_file in tqdm(info_files):\n",
    "    with open(info_file, \"r\") as f:\n",
    "        info = json.load(f)\n",
    "    info[\"is_valid\"] = True\n",
    "    with open(info_file, \"w\") as f:\n",
    "        json.dump(info, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
