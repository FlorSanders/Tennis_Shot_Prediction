{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D -> 3D Data Processing\n",
    "Execution of this notebook is meant to follow `1_data_processing.ipynb`. \n",
    "\n",
    "The "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import cv2\n",
    "\n",
    "# Constants\n",
    "from __init__ import data_path\n",
    "from data_utils import read_segment_frames, read_segment_labels, visualize_frame_annotations, visualize_segment_labels\n",
    "\n",
    "# Choose dataset\n",
    "dataset_path = \"/home/florsanders/adl_ai_tennis_coach/data/tenniset\"\n",
    "write_path = \"/home/georgetamer/3d_poses\"\n",
    "segments_path = os.path.join(dataset_path, \"segments\")\n",
    "labels_path = os.path.join(dataset_path,\"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_frame(frame,\n",
    "              bbox,\n",
    "              crop_padding=50,\n",
    "            crop_img_width=256):\n",
    "    # Frame size\n",
    "    frame_height, frame_width = frame.shape[:2]\n",
    "\n",
    "    # Parse bounding box coords\n",
    "    if np.any(bbox == None):\n",
    "        return best_keypoints, best_bbox\n",
    "    x1, y1, x2, y2 = bbox\n",
    "    xc, yc =  (x1 + x2) / 2, (y1 + y2) / 2\n",
    "    w, h = abs(x2 - x1), abs(y2 - y1)\n",
    "    d = max(w, h) + crop_padding * 2\n",
    "\n",
    "    # Define cropping indices\n",
    "    x_crop1, x_crop2 = int(xc - d/2), int(xc + d/2)\n",
    "    y_crop1, y_crop2 = int(yc - d/2), int(yc + d/2)\n",
    "\n",
    "    # Make sure we don't crop past the edges of the frame\n",
    "    x_crop_offset = min(frame_width - x_crop2, max(-x_crop1, 0))\n",
    "    y_crop_offset = min(frame_height - y_crop2, max(-y_crop1, 0))\n",
    "    x_crop1 += x_crop_offset\n",
    "    x_crop2 += x_crop_offset\n",
    "    y_crop1 += y_crop_offset\n",
    "    y_crop2 += y_crop_offset\n",
    "    \n",
    "    # Crop image\n",
    "    img = frame[y_crop1:y_crop2,  x_crop1:x_crop2].copy()\n",
    "\n",
    "    # Resize img\n",
    "    scale = d / crop_img_width\n",
    "    img = cv2.resize(img, (crop_img_width, crop_img_width))\n",
    "    return img\n",
    "\n",
    "def detect_pose(\n",
    "    frame,\n",
    "    bbox,\n",
    "    crop_padding=50,\n",
    "    crop_img_width=256\n",
    "):\n",
    "\n",
    "    # Crop image\n",
    "    crop_padding=10\n",
    "    cropped_frame = crop_frame(frame, bbox, crop_padding,crop_img_width)\n",
    "\n",
    "    # Detect pose\n",
    "    should_show = False\n",
    "    result_generator = inferencer(cropped_frame, show=should_show, vis_out_dir=\"/home/georgetamer/3d_poses\", return_vis=True)\n",
    "    results = [result for result in result_generator]\n",
    "\n",
    "    # # Parse keypoints\n",
    "    # min_center_distance = np.inf\n",
    "    # result = results[0]\n",
    "    # prediction = result[\"predictions\"][0]\n",
    "    # item = prediction[0]\n",
    "    # keypoints = item[\"keypoints\"]\n",
    "\n",
    "    # Keep best results\n",
    "    min_center_distance = np.inf\n",
    "    for result in results:\n",
    "        print(\"result: \", result)\n",
    "        for prediction in result[\"predictions\"]:\n",
    "            for item in prediction:\n",
    "                # Parse item\n",
    "                # pose_bbox = item[\"bbox\"]\n",
    "                keypoints = item[\"keypoints\"]\n",
    "\n",
    "                # Parse bbox\n",
    "                # xb1, yb1, xb2, yb2 = pose_bbox[0]\n",
    "                # center_x = (xb1 + xb2) / 2\n",
    "                # center_y = (yb1 + yb2) / 2\n",
    "                # center_distance = ((crop_img_width / 2 - center_x)**2  + (crop_img_width / 2 - center_y)**2)**(1/2)\n",
    "\n",
    "                # # Keep track of best prediction\n",
    "                # if center_distance < min_center_distance:\n",
    "                #     min_center_distance = center_distance\n",
    "                #     best_keypoints = keypoints\n",
    "                #     best_bbox = pose_bbox[0]\n",
    "\n",
    "    return np.array(keypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_bbox_sequence(\n",
    "    bbox_sequence, \n",
    "    court_sequence, \n",
    "    is_btm,\n",
    "    derivative_threshold=5000,\n",
    "    make_plot=False,\n",
    "):\n",
    "    # Look at center points to gather inconsistencies\n",
    "    center_points = np.zeros((len(bbox_sequence), 2))\n",
    "    bbox_areas = np.zeros(len(bbox_sequence))\n",
    "    bbox_sequence_clean = np.copy(bbox_sequence)\n",
    "    missing_points = np.zeros(len(center_points), dtype=int)\n",
    "\n",
    "    # Extract center points wrt court from \n",
    "    for i, (bbox, court_points) in enumerate(zip(bbox_sequence, court_sequence)):\n",
    "        # Skip no bounding box detected\n",
    "        if np.any(bbox == None):\n",
    "            center_points[i, :] = np.inf\n",
    "            continue\n",
    "        xb1, yb1, xb2, yb2 = bbox\n",
    "        bbox_areas[i] = np.abs((xb2 - xb1) * (yb2 - yb1))\n",
    "\n",
    "        # Skip no court outline detected\n",
    "        court_outline = court_points[:4]\n",
    "        if np.any(court_outline == None):\n",
    "            center_points[i, :] = np.inf\n",
    "            continue\n",
    "        \n",
    "        # Get relevant center point of the court\n",
    "        (xtl, ytl), (xtr, ytr), (xbl, ybl), (xbr, ybr) = court_outline\n",
    "        x_ref = (xbl + xbr) / 2 if is_btm else (xtl + xtr) / 2\n",
    "        y_ref = (ybl + ybr) / 2 if is_btm else (ytl + ytr) / 2\n",
    "\n",
    "        # Get center point of the player's feet\n",
    "        x_player = (xb1 + xb2) / 2\n",
    "        y_player = yb2\n",
    "\n",
    "        # Save player center point referenced to court point\n",
    "        center_points[i, 0] = x_player - x_ref\n",
    "        center_points[i, 1] = y_player - y_ref\n",
    "\n",
    "    # Compute first derivative\n",
    "    center_points_derivative = np.vstack(([[0, 0]], center_points[:-1] - center_points[1:]))\n",
    "    center_points_derivative = center_points_derivative[:,0]**2 + center_points_derivative[:,1]**2\n",
    "    bbox_areas_derivative = np.abs(np.concatenate(([0], bbox_areas[:-1] - bbox_areas[1:])))\n",
    "\n",
    "    # Area jumps\n",
    "    bbox_area_jumps = np.sort(np.argwhere(bbox_areas_derivative > derivative_threshold).reshape(-1))\n",
    "    if len(bbox_area_jumps):\n",
    "        # print(\"JUMPS DETECTED\")\n",
    "        # print(bbox_area_jumps)\n",
    "        mean_area = np.mean(bbox_areas[:bbox_area_jumps[0]])\n",
    "    else:\n",
    "        mean_area = np.mean(bbox_areas)\n",
    "\n",
    "    # Determine jump points\n",
    "    jump_points = np.argwhere(np.logical_or(\n",
    "        center_points_derivative > derivative_threshold,\n",
    "        bbox_areas < mean_area / 2,\n",
    "    )).reshape(-1)\n",
    "    \n",
    "    # Return if no cleaning needs to be done\n",
    "    if len(jump_points) == 0:\n",
    "        return missing_points.astype(bool), bbox_sequence_clean\n",
    "\n",
    "    # Process jump points\n",
    "    indx_last = None\n",
    "    missing_start = False\n",
    "    for indx in jump_points:\n",
    "        #print(indx_last, indx)\n",
    "        if indx_last is None:\n",
    "            # First missing point\n",
    "            #print(\"FIRST MISSING POINT\")\n",
    "            missing_points[indx] = 1\n",
    "            missing_start = True\n",
    "        elif np.any(bbox_sequence[indx] == None):\n",
    "            # Missing point\n",
    "            #print(\"MISSING POINT\", indx)\n",
    "            missing_points[indx] = 1\n",
    "            missing_start = False\n",
    "        elif indx_last == indx - 1:\n",
    "            # Subsequent problematic points\n",
    "            #print(\"SUBSEQUENT MISSING POINT\")\n",
    "            missing_points[indx] = 1\n",
    "            missing_start = False\n",
    "        else:\n",
    "            # Distance between missing points\n",
    "            #print(\"DISTANCE BETWEEN MISSING POINTS\")\n",
    "            if missing_start:\n",
    "                # End point (hopefully)\n",
    "                missing_points[indx_last:indx+1] = 1\n",
    "                missing_start = False\n",
    "            else:\n",
    "                # Start point (hopefully)\n",
    "                missing_points[indx] = 1\n",
    "                missing_start = True\n",
    "\n",
    "        # Update last indx\n",
    "        indx_last = indx\n",
    "\n",
    "    # Fill gaps in missing points by linear interpolation\n",
    "    filled_center_points = np.copy(center_points)\n",
    "    missing_starts = np.argwhere((missing_points[1:] - missing_points[:-1]) == 1).reshape(-1)\n",
    "    missing_ends = np.argwhere((missing_points[1:] - missing_points[:-1]) == -1).reshape(-1)\n",
    "    for i, missing_start in enumerate(missing_starts):\n",
    "        # Get start value\n",
    "        if missing_start != 0:\n",
    "            # Previous value\n",
    "            cp_start_value = filled_center_points[missing_start-1]\n",
    "            bbox_start_value = bbox_sequence_clean[missing_start-1]\n",
    "        else:\n",
    "            # First valid value (TODO: fix if none is valid???)\n",
    "            cp_start_value = filled_center_points[not missing_points.astype(bool)][0]\n",
    "            bbox_start_value = bbox_sequence_clean[not missing_points.astype(bool)][0]\n",
    "\n",
    "        # Get missing end\n",
    "        if len(missing_ends) <= i:\n",
    "            # No matched endpoint - constant from startpoint onward\n",
    "            missing_end = len(filled_center_points) - 1\n",
    "            cp_end_value = cp_start_value\n",
    "            bbox_end_value = bbox_start_value\n",
    "        else:\n",
    "            # Get endpoint\n",
    "            missing_end = missing_ends[i]\n",
    "            cp_end_value = filled_center_points[missing_end]\n",
    "            bbox_end_value = bbox_sequence_clean[missing_end]\n",
    "            \n",
    "        # Linearly interpolate\n",
    "        n_points = missing_end - missing_start + 1\n",
    "        filled_center_points[missing_start:missing_end+1] = np.linspace(cp_start_value, cp_end_value, n_points)\n",
    "        bbox_sequence_clean[missing_start:missing_end+1] = np.linspace(bbox_start_value, bbox_end_value, n_points)\n",
    "\n",
    "    return missing_points.astype(bool), bbox_sequence_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_segment(\n",
    "    segment_path, \n",
    "    labels_path=labels_path,\n",
    "    crop_padding=50,\n",
    "    crop_width=224,\n",
    "):\n",
    "    # Load frames\n",
    "    segment_dir, segment_filename = os.path.split(segment_path)\n",
    "    segment_name, segment_ext = os.path.splitext(segment_filename)\n",
    "    frames, fps = read_segment_frames(segment_path, labels_path=labels_path, load_valid_frames_only=True)\n",
    "    if not len(frames):\n",
    "        return False\n",
    "\n",
    "    # Load labels\n",
    "    (\n",
    "        _,\n",
    "        court_sequence,\n",
    "        _,\n",
    "        player_btm_bbox_sequence,\n",
    "        player_top_bbox_sequence,\n",
    "        _,\n",
    "        _,\n",
    "    ) = read_segment_labels(\n",
    "        segment_path, \n",
    "        labels_path=labels_path,\n",
    "        load_frame_validity=True,\n",
    "        load_court=True,\n",
    "        load_ball=False,\n",
    "        load_player_bbox=True,\n",
    "        load_player_pose=False,\n",
    "        use_pose_bbox=True,\n",
    "    )\n",
    "\n",
    "    btm_missing_points, btm_bbox_clean = clean_bbox_sequence(\n",
    "        player_btm_bbox_sequence,\n",
    "        court_sequence,\n",
    "        is_btm=True,\n",
    "        make_plot=True,\n",
    "    )\n",
    "    top_missing_points, top_bbox_clean = clean_bbox_sequence(\n",
    "        player_top_bbox_sequence,\n",
    "        court_sequence,\n",
    "        is_btm=False,\n",
    "        make_plot=True,\n",
    "    )\n",
    "\n",
    "    # Process frames\n",
    "    players_bbox_last = [None, None]\n",
    "    players_bbox_sequences = [[None] *  len(frames) , [None] * len(frames)]\n",
    "    players_pose_sequences = [[None] *  len(frames) , [None] * len(frames)]\n",
    "    for frame_index, frame in tqdm(enumerate(frames)):\n",
    "        # Get frame labels\n",
    "        frame_height, frame_width, _ = frame.shape\n",
    "        players_bbox = [player_top_bbox_sequence[frame_index], player_btm_bbox_sequence[frame_index]]\n",
    "        players_bbox_clean = [top_bbox_clean[frame_index], btm_bbox_clean[frame_index]]\n",
    "        players_missing = [top_missing_points[frame_index], btm_missing_points[frame_index]]\n",
    "\n",
    "        # Perform pose detection\n",
    "        for is_btm, bbox in enumerate(players_bbox):\n",
    "            if players_missing[is_btm]:\n",
    "                # Try to recover player pose from best knowledge\n",
    "                for i, bbox_candidate in enumerate([players_bbox_last[is_btm], players_bbox_clean[is_btm], players_bbox[is_btm]]):\n",
    "                    # Skip invalid bboxes\n",
    "                    if bbox_candidate is None:\n",
    "                        continue\n",
    "                    \n",
    "                    # Detect pose\n",
    "                    pose_keypoints = detect_pose(\n",
    "                        frame, \n",
    "                        bbox_candidate, \n",
    "                        crop_padding=crop_padding, \n",
    "                        crop_img_width=crop_width,\n",
    "                    )\n",
    "\n",
    "                    # Break if result is valid\n",
    "                    if not np.any(pose_keypoints == None):\n",
    "                        break\n",
    "            else:\n",
    "                # Detect pose\n",
    "                pose_keypoints = detect_pose(\n",
    "                    frame, \n",
    "                    bbox, \n",
    "                    crop_padding=crop_padding, \n",
    "                    crop_img_width=crop_width\n",
    "                )\n",
    "\n",
    "            # Save pose\n",
    "            players_pose_sequences[is_btm][frame_index] = pose_keypoints\n",
    "                    \n",
    "\n",
    "    # Export labels\n",
    "    for is_btm in range(2):\n",
    "        player_name = \"btm\" if is_btm else \"top\"\n",
    "        player_3d_pose_file = os.path.join(write_path, f\"{segment_name}_player_{player_name}_pose_3d.npy\")\n",
    "        np.save(player_3d_pose_file, players_pose_sequences[is_btm])\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_path = os.path.join(segments_path, \"V009_0061.mp4\")\n",
    "print(\"Segment path\", seg_path)\n",
    "\n",
    "success = process_segment(\n",
    "    segment_path=seg_path, \n",
    "    labels_path=labels_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the .npy file\n",
    "sample_file = os.path.join(write_path, 'V009_0061_player_top_pose_3d.npy')\n",
    "# sample_file = os.path.join(labels_path, 'V010_0071_player_top_bbox.npy')\n",
    "data = np.load(sample_file, allow_pickle=True)\n",
    "\n",
    "# Print the contents of the file\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # visualize\n",
    "# from mmpose.apis import visualize\n",
    "\n",
    "# # extract first frame from segment\n",
    "# img_path = os.path.join(write_path, '000000.jpg')\n",
    "# keypoints = np.load(sample_file, allow_pickle=True)\n",
    "# keypoint_scores = None\n",
    "\n",
    "# metainfo = 'config/_base_/datasets/coco.py'\n",
    "\n",
    "# visualize(\n",
    "#     img_path,\n",
    "#     keypoints,\n",
    "#     keypoint_scores,\n",
    "#     metainfo=metainfo,\n",
    "#     show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take heuristic such as max area, or largest x-span, y-span\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
