{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Shot Segmentation\n",
    "\n",
    "In the initial data processing notebook, the tennis matches were split into point segments.  \n",
    "However, the downstream goals have shifted and the tennis matches and its annotations should now be split into shot segments.  \n",
    "This is a patch notebook that takes care of mapping the point segments labels to shot segment labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step X - Map tennis point segments to shot segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___VIDEOS___\n",
      "V006.mp4\n",
      "V007.mp4\n",
      "V008.mp4\n",
      "V009.mp4\n",
      "V010.mp4\n"
     ]
    }
   ],
   "source": [
    "# Constants\n",
    "from __init__ import data_path\n",
    "\n",
    "# Choose dataset\n",
    "dataset = \"tenniset\"\n",
    "dataset_path = os.path.join(data_path, dataset)\n",
    "videos_path = os.path.join(dataset_path, \"videos\")\n",
    "annotations_path = os.path.join(dataset_path, \"annotations\")\n",
    "segments_path = os.path.join(dataset_path, \"segments\")\n",
    "labels_path = os.path.join(dataset_path, \"labels\")\n",
    "\n",
    "# Read videos\n",
    "videos = sorted(os.listdir(videos_path))\n",
    "print(\"___VIDEOS___\")\n",
    "for video in videos: \n",
    "    print(video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new directories for the shot segments and shot labels\n",
    "shot_segments_path = os.path.join(dataset_path, \"shot_segments\")\n",
    "shot_labels_path = os.path.join(dataset_path, \"shot_labels\")\n",
    "os.makedirs(shot_segments_path, exist_ok=True)\n",
    "os.makedirs(shot_labels_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_to_timestamp(frame_nr, fps=25):\n",
    "    timestamp_seconds = frame_nr / fps\n",
    "    timestamp_minutes = int(timestamp_seconds / 60)\n",
    "    timestamp_seconds = int(timestamp_seconds % 60)\n",
    "    return f\"{timestamp_minutes:02d}:{timestamp_seconds:02d}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import read_segment_frames, read_segment_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video: V006.mp4\n",
      " - Number of point splits: 81\n",
      " - Number of hit and serve splits: 332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|â–‹         | 21/332 [00:13<03:25,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Following split indices are missing\n",
      "V006.mp4: 3 - [6, 8, 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "missing_splits = {}\n",
    "for video in videos:\n",
    "    missing_splits[video] = []\n",
    "    print(f\"Processing video: {video}\")\n",
    "    # Video & annotation path\n",
    "    video_name, video_ext = os.path.splitext(video)\n",
    "    annotation_path = os.path.join(annotations_path, video.replace(video_ext, \".json\"))\n",
    "\n",
    "    # Load annotation\n",
    "    with open(annotation_path) as annotation_file:\n",
    "        annotation = json.load(annotation_file)\n",
    "    \n",
    "    # Load point segment split points\n",
    "    point_splits = annotation[\"classes\"][\"Point\"]\n",
    "    print(f\" - Number of point splits: {len(point_splits)}\")\n",
    "    point_split_start_frames = np.array([split[\"start\"] for split in point_splits])\n",
    "    point_split_end_frames = np.array([split[\"end\"] for split in point_splits])\n",
    "\n",
    "    # Load hit segments\n",
    "    set_splits = annotation[\"classes\"][\"Set\"]\n",
    "    hit_splits = annotation[\"classes\"][\"Hit\"]\n",
    "    serve_splits = annotation[\"classes\"][\"Serve\"]\n",
    "    hits_and_serve_splits = sorted(hit_splits + serve_splits, key=lambda x: x[\"start\"])\n",
    "    # Process hit segments\n",
    "    print(f\" - Number of hit and serve splits: {len(hits_and_serve_splits)}\")\n",
    "    for split_index, split in enumerate(tqdm(hits_and_serve_splits)):\n",
    "        # Parse split information\n",
    "        split_name = f\"{split_index}\".zfill(4)\n",
    "        split_name = f\"{video_name}_{split_name}\"\n",
    "        start_frame = split[\"start\"]\n",
    "        end_frame = split[\"end\"]\n",
    "\n",
    "        # Figure out which player is performing the shot\n",
    "        split_set = [set_split for set_split in set_splits if set_split[\"start\"] <= start_frame and set_split[\"end\"] >= end_frame]\n",
    "        assert len(split_set) == 1, f\"Hit segment {split_index} is part of {len(split_set)} set segments\"\n",
    "        split_set = split_set[0]\n",
    "        near_player = split_set[\"custom\"][\"Near\"]\n",
    "        split_player = split[\"custom\"][\"Player\"]\n",
    "        split_info = {\n",
    "            \"player\": split_player,\n",
    "            \"player_is_near\":  near_player == split_player,\n",
    "        }\n",
    "\n",
    "        # Find point segment that this hit segment is part of\n",
    "        mask_1 = start_frame >= point_split_start_frames\n",
    "        mask_2 = end_frame <= point_split_end_frames\n",
    "        mask = np.logical_and(mask_1, mask_2)\n",
    "        indx = np.argwhere(mask).reshape(-1)\n",
    "\n",
    "        # Handle case where both segments are not fully aligned\n",
    "        if len(indx) == 0:\n",
    "            #print(f\"WARNING: Hit segment {split_index} not fully contained in any point segment, marking missing\")\n",
    "            missing_splits[video].append(split_index)\n",
    "            continue\n",
    "\n",
    "        # Make sure everythin makes sense\n",
    "        assert len(indx) > 0, f\"Hit segment {split_index} is part of no known point segment\"\n",
    "        assert len(indx) == 1, f\"Hit segment {split_index} is part of multiple point segments\"\n",
    "        indx = indx[0]\n",
    "        point_start_frame = point_split_start_frames[indx]\n",
    "        point_end_frame = point_split_end_frames[indx]\n",
    "        assert point_start_frame <= start_frame and point_end_frame >= end_frame, f\"Hit segment {split_index} is not fully contained in point segment {indx}\"\n",
    "\n",
    "        # Load frames for the point segments\n",
    "        point_split_name = f\"{indx}\".zfill(4)\n",
    "        point_segment_path = os.path.join(segments_path, f\"{video_name}_{point_split_name}.mp4\")\n",
    "        point_frames, fps = read_segment_frames(point_segment_path, labels_path=labels_path, load_valid_frames_only=False)\n",
    "        assert point_end_frame - point_start_frame == len(point_frames), f\"Unexpected number of point segment frames\"\n",
    "        \n",
    "        # Load labels for the point segment\n",
    "        # TODO: Load 3D Annotations\n",
    "        (\n",
    "            frame_validity,\n",
    "            court_sequence,\n",
    "            ball_sequence,\n",
    "            player_btm_bbox_pose_sequence,\n",
    "            player_top_bbox_pose_sequence,\n",
    "            player_btm_pose_sequence,\n",
    "            player_top_pose_sequence,\n",
    "        ) = read_segment_labels(\n",
    "            point_segment_path,\n",
    "            labels_path=labels_path,\n",
    "            load_frame_validity=True,\n",
    "            load_court=True,\n",
    "            load_ball=True,\n",
    "            load_player_bbox=True,\n",
    "            load_player_pose=True,\n",
    "            use_pose_bbox=True,\n",
    "        )\n",
    "        (\n",
    "            _,\n",
    "            _,\n",
    "            _,\n",
    "            player_btm_bbox_sequence,\n",
    "            player_top_bbox_sequence,\n",
    "            _,\n",
    "            _,\n",
    "        ) = read_segment_labels(\n",
    "            point_segment_path,\n",
    "            labels_path=labels_path,\n",
    "            load_frame_validity=False,\n",
    "            load_court=False,\n",
    "            load_ball=False,\n",
    "            load_player_bbox=True,\n",
    "            load_player_pose=False,\n",
    "            use_pose_bbox=False,\n",
    "        )\n",
    "        \n",
    "        # Extract frames, frame validity for the hit segment\n",
    "        start_index = int(start_frame - point_start_frame)\n",
    "        end_index = int(end_frame - point_start_frame)\n",
    "        split_frames = point_frames[start_index:end_index]\n",
    "        split_frame_validity = frame_validity[start_index:end_index]\n",
    "\n",
    "        # Extract the labels for the valid frames\n",
    "        start_label_index = np.count_nonzero(frame_validity[:start_index])\n",
    "        end_label_index = np.count_nonzero(frame_validity[:end_index])\n",
    "        split_court_sequence = court_sequence[start_label_index:end_label_index]\n",
    "        split_ball_sequence = ball_sequence[start_label_index:end_label_index]\n",
    "        split_player_btm_bbox_sequence = player_btm_bbox_sequence[start_label_index:end_label_index]\n",
    "        split_player_top_bbox_sequence = player_top_bbox_sequence[start_label_index:end_label_index]\n",
    "        split_player_btm_bbox_pose_sequence = player_btm_bbox_pose_sequence[start_label_index:end_label_index]\n",
    "        split_player_top_bbox_pose_sequence = player_top_bbox_pose_sequence[start_label_index:end_label_index]\n",
    "        split_player_btm_pose_sequence = player_btm_pose_sequence[start_label_index:end_label_index]\n",
    "        split_player_top_pose_sequence = player_top_pose_sequence[start_label_index:end_label_index]\n",
    "        # TODO: Add 3D Annotations\n",
    "\n",
    "        # Sanity checks\n",
    "        assert np.count_nonzero(split_frame_validity) == len(split_court_sequence), f\"Extracted court sequence has wrong length\"\n",
    "        assert np.count_nonzero(split_frame_validity) == len(split_ball_sequence), f\"Extracted ball sequence has wrong length\"\n",
    "        assert np.count_nonzero(split_frame_validity) == len(split_player_btm_bbox_sequence), f\"Extracted bottom player bbox sequence has wrong length\"\n",
    "        assert np.count_nonzero(split_frame_validity) == len(split_player_top_bbox_sequence), f\"Extracted top player bbox sequence has wrong length\"\n",
    "        assert np.count_nonzero(split_frame_validity) == len(split_player_btm_bbox_pose_sequence), f\"Extracted bottom player bbox pose sequence has wrong length\"\n",
    "        assert np.count_nonzero(split_frame_validity) == len(split_player_top_bbox_pose_sequence), f\"Extracted top player bbox pose sequence has wrong length\"\n",
    "        assert np.count_nonzero(split_frame_validity) == len(split_player_btm_pose_sequence), f\"Extracted bottom player pose sequence has wrong length\"\n",
    "        assert np.count_nonzero(split_frame_validity) == len(split_player_top_pose_sequence), f\"Extracted top player pose sequence has wrong length\"\n",
    "        # TODO: Add 3D Annotations\n",
    "\n",
    "        # Save split info\n",
    "        with open(os.path.join(shot_labels_path, f\"{split_name}_info.json\"), \"w\") as f:\n",
    "            json.dump(split_info, f)\n",
    "\n",
    "        # Save video\n",
    "        frame_height, frame_width, _ = split_frames[0].shape\n",
    "        split_video_path = os.path.join(shot_segments_path, f\"{split_name}.mp4\")\n",
    "        writer = cv2.VideoWriter(split_video_path, cv2.VideoWriter_fourcc(*\"avc1\"), fps, (frame_width, frame_height))\n",
    "        for frame in split_frames:\n",
    "            writer.write(frame)\n",
    "        writer.release()\n",
    "\n",
    "        # Save labels\n",
    "        np.save(os.path.join(shot_labels_path, f\"{split_name}_frame_validity.npy\"), split_frame_validity)\n",
    "        np.save(os.path.join(shot_labels_path, f\"{split_name}_court.npy\"), split_court_sequence)\n",
    "        np.save(os.path.join(shot_labels_path, f\"{split_name}_ball.npy\"), split_ball_sequence)\n",
    "        np.save(os.path.join(shot_labels_path, f\"{split_name}_player_btm_bbox.npy\"), split_player_btm_bbox_sequence)\n",
    "        np.save(os.path.join(shot_labels_path, f\"{split_name}_player_top_bbox.npy\"), split_player_top_bbox_sequence)\n",
    "        np.save(os.path.join(shot_labels_path, f\"{split_name}_player_btm_bbox_pose.npy\"), split_player_btm_bbox_pose_sequence)\n",
    "        np.save(os.path.join(shot_labels_path, f\"{split_name}_player_top_bbox_pose.npy\"), split_player_top_bbox_pose_sequence)\n",
    "        np.save(os.path.join(shot_labels_path, f\"{split_name}_player_btm_pose.npy\"), split_player_btm_pose_sequence)\n",
    "        np.save(os.path.join(shot_labels_path, f\"{split_name}_player_top_pose.npy\"), split_player_top_pose_sequence)\n",
    "        \n",
    "        \n",
    "        if split_index > 20:\n",
    "            break\n",
    "\n",
    "\n",
    "        #print(point_split_name)\n",
    "        \n",
    "    print()\n",
    "    break\n",
    "\n",
    "\n",
    "print(\"Following split indices are missing\")\n",
    "for key, value in missing_splits.items():\n",
    "    print(f\"{key}: {len(value)} - {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video: V006.mp4\n",
      " - Number of point splits: 81\n",
      " - Number of hit and serve splits: 332\n",
      "{'custom': {'Player': 'Williams', 'Result': 'Fault'}, 'name': '0004', 'start': 27708, 'desc': '', 'end': 27779}\n",
      "/home/florsanders/Code/columbia_university/advanced_deep_learning/adl_ai_tennis_coach/data/tenniset/shot_segments/V006_0006.mp4\n",
      "{'custom': {'Player': 'Williams', 'Result': 'Fault'}, 'name': '0004', 'start': 27708, 'desc': '', 'end': 27779}\n",
      "/home/florsanders/Code/columbia_university/advanced_deep_learning/adl_ai_tennis_coach/data/tenniset/shot_segments/V006_0008.mp4\n",
      "{'custom': {'Player': 'Williams', 'Result': 'Fault'}, 'name': '0006', 'start': 29302, 'desc': '', 'end': 29365}\n",
      "/home/florsanders/Code/columbia_university/advanced_deep_learning/adl_ai_tennis_coach/data/tenniset/shot_segments/V006_0015.mp4\n"
     ]
    }
   ],
   "source": [
    "# Extract segment videos from full \n",
    "for video, missing_indxs in missing_splits.items():\n",
    "    print(f\"Processing video: {video}\")\n",
    "    # Video & annotation path\n",
    "    video_name, video_ext = os.path.splitext(video)\n",
    "    annotation_path = os.path.join(annotations_path, video.replace(video_ext, \".json\"))\n",
    "    video_path = os.path.join(videos_path, video)\n",
    "\n",
    "    # Load annotation\n",
    "    with open(annotation_path) as annotation_file:\n",
    "        annotation = json.load(annotation_file)\n",
    "\n",
    "    # Load video\n",
    "    capture = cv2.VideoCapture(video_path)\n",
    "    frame = 0\n",
    "\n",
    "    # Get resolution & framerate from capture\n",
    "    frame_width = int(capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = capture.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    # Load point segment split points\n",
    "    point_splits = annotation[\"classes\"][\"Point\"]\n",
    "    print(f\" - Number of point splits: {len(point_splits)}\")\n",
    "    point_split_start_frames = np.array([split[\"start\"] for split in point_splits])\n",
    "    point_split_end_frames = np.array([split[\"end\"] for split in point_splits])\n",
    "\n",
    "    # Load hit segments\n",
    "    set_splits = annotation[\"classes\"][\"Set\"]\n",
    "    hit_splits = annotation[\"classes\"][\"Hit\"]\n",
    "    serve_splits = annotation[\"classes\"][\"Serve\"]\n",
    "    hits_and_serve_splits = sorted(hit_splits + serve_splits, key=lambda x: x[\"start\"])\n",
    "\n",
    "    # Process hit segments\n",
    "    print(f\" - Number of hit and serve splits: {len(hits_and_serve_splits)}\")\n",
    "    for indx in tqdm(missing_indxs):\n",
    "        # Parse split information\n",
    "        split_name = f\"{indx}\".zfill(4)\n",
    "        split_name = f\"{video_name}_{split_name}\"\n",
    "        split = hits_and_serve_splits[indx]\n",
    "        start, end = int(split[\"start\"]), int(split[\"end\"])\n",
    "\n",
    "        # Figure out which player is performing the shot\n",
    "        split_set = [set_split for set_split in set_splits if set_split[\"start\"] <= start_frame and set_split[\"end\"] >= end_frame]\n",
    "        assert len(split_set) == 1, f\"Hit segment {split_index} is part of {len(split_set)} set segments\"\n",
    "        split_set = split_set[0]\n",
    "        near_player = split_set[\"custom\"][\"Near\"]\n",
    "        split_player = split[\"custom\"][\"Player\"]\n",
    "        split_info = {\n",
    "            \"player\": split_player,\n",
    "            \"player_is_near\":  near_player == split_player,\n",
    "        }\n",
    "\n",
    "        # Save split info\n",
    "        with open(os.path.join(shot_labels_path, f\"{split_name}_info.json\"), \"w\") as f:\n",
    "            json.dump(split_info, f)\n",
    "\n",
    "        # Fast forward to start of segment\n",
    "        frame = start\n",
    "        capture.set(1, frame)\n",
    "\n",
    "        # Open writer\n",
    "        split_video_path = os.path.join(shot_segments_path, f\"{split_name}.mp4\")\n",
    "        writer = cv2.VideoWriter(split_video_path, cv2.VideoWriter_fourcc(*\"avc1\"), fps, (frame_width, frame_height))\n",
    "\n",
    "        # Save frames to segment\n",
    "        while_safety = 0\n",
    "        max_while_safety = 500\n",
    "        while frame < end:\n",
    "            # Read frame\n",
    "            ret, img = capture.read()\n",
    "\n",
    "            # Sometimes OpenCV reads None's during a video, in which case we want to just skip\n",
    "            assert while_safety < max_while_safety, f\"ERROR, cv2 read {max_while_safety} Nones\"\n",
    "            if ret == 0 or img is None: \n",
    "                while_safety += 1\n",
    "                continue \n",
    "            while_safety = 0\n",
    "\n",
    "            # Write frame\n",
    "            writer.write(img)\n",
    "\n",
    "            # Increase frame counter\n",
    "            frame += 1\n",
    "\n",
    "        # Release writer\n",
    "        writer.release()\n",
    "    \n",
    "    capture.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "teco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
